[
["index.html", "Data Science for Public Health Economic Evaluation Chapter 1 Background 1.1 Who are we: 1.2 Our series of Short Courses in R. 1.3 Aim of the series of courses", " Data Science for Public Health Economic Evaluation Robert Smith 2020-05-21 Chapter 1 Background 1.1 Who are we: All of the tutors on the course are PhD candidates in the Wellcome Trust Doctoral Training Centre for Public Health Economics and Decision Science at the School of Health and Related Research at the University of Sheffield. Robert Smith joined ScHARR in 2016. His research focuses on the methods used to estimate the costs and benefits of public health interventions, with a specific interest in microsimulation modelling (done in R). He has become increasingly intersted in the use of R-Markdown and R-Shiny to make research more transparent and to aid decision makers. While doing his PhD, Robert has been involved in projects with the WHO and Parkrun. Paul Schneider joined ScHARR in 2018. He is working on conceptual and methodological problems in valuing health outcomes in economic evaluations. A medical doctor and epidemiologist by training, he has used R in various research projects, ranging from the modeling costs of breast cancer, and value of information analyses, to the monitoring of influenza in real-time using online data. He is a keen advocate of open science practices. 1.2 Our series of Short Courses in R. Below is a list of our planned short courses in R. 1.2.1 Course 1 - Intro to R By the end of the one day short course, the attendee should be able to: Install and navigate R Studio. Set the working directory. Understand the types of objects and basic operations in R. Read in data from csv and excel files. Summarise data. Know where to find further information. 1.2.2 Course 2 - Intermediate R By the end of the half day short course, the attendee should be able to: Find &amp; download appropriate packages for different tasks. Use tidyverse functions to manipulate data. Use the dplyr package to mutate, select, filter, summarise and arrange data. Analyse datasets by groups. Use tidyr to restructure data. Know where to find further information. 1.2.3 Course 3 - Beautiful Visualisations By the end of the half day short course, the attendee should be able to: Know the benefits of ggplot over base R. Structure data efficiently to enable the use of ggplot. Understand the basic types of plots and when to use them. Create beautiful visualisations using ggplot2. Use geographical data to produce choropleth maps. 1.2.4 Course 4 - R for Health Economics By the end of the one day short course, the attendee should also be able to: Understand the strengths and limitations of R for health economic modelling. Manage different objects and parameters in R. Use loops, custom functions and the apply family. Create a markov model from scratch given known parameters. Create a microsimulation model to incorporate hetrogeneity between groups. Understand the importance of tranparency of coding. In particular commenting. 1.2.5 Course 5 - R Shiny for decision modelling By the end of the half day short course, the attendee should be able to: Understand the benefits and limitations of R-Shiny. Have a basic understanding of the principles behind R-Shiny. Create an R-Shiny application from scratch. Integrate beautiful plots into R-Shiny. Develop a user interface for an existing markov model in R-Shiny. Know where to find further information. 1.2.6 Course 6 - Collaboration in R By the end of the half day short course, the attendee should be able to: Understand the strengths and limitations of R-Markdown. Create replicatable HTML, Word and PDF documents using R-Markdown. Include chunks of code, graphs, references and biblographies, links to websites and pictures within documents. Collaborate on a project in GitHub Replicate analysis for new or updated datasets from previous work made publicly available on GitHub. 1.3 Aim of the series of courses This series of short courses are designed to equip the participant with a basic set of tools to undertake research using R. The aim is to create a strong foundation on which participants can build skills and knowledge specific to their research and consultancy objectives. The course makes use of the authors’ experiences (many of which were frustrating) of working with R for data-science and statistical analysis. However there are many other resources available, and we would particularly recommend the freely available content at R for Data Science as a good place to recap the materials taught in this course. The hard copy of Hadley Wickham and Garrett Grolemund’s book of the same name (and content) is available at Amazon.com. Alternatively, a user guide is available on the CRAN R-Project website here, although the author finds this less easy to follow than Hadley Wickham’s book described above. Further details of where to go to answer more specific questions are provided throughout the course. Requirements: It is assumed that all participants on the course have their own laptop, and have previously used software such as Excel or SPSS. Some basic understanding of statistics and mathematics is required (e.g. mean, median, minimum, maximum). "],
["intro.html", "Chapter 2 Introduction to R 2.1 Install and navigate R Studio. 2.2 Basics 2.3 Object classes and types 2.4 Working with Data in R 2.5 Further learning", " Chapter 2 Introduction to R 2.1 Install and navigate R Studio. R is a free software environment for statistical analysis and data science. It is a collaborative effort started by Robert Gentleman and Ross Ihaka in New Zealand, but now made up of hundreds of people. R is made freely available by the Comprehensive R archive Network (CRAN), in the UK it can be downloaded through the University of Bristol here.There are options of downloading R for Linux, Max and Windows. Downloading R gives you the basic software environment, but an incredibly popular add-on called ‘RStudio’ is required to follow this course. You should download the free ‘RStudio Desktop Open Source Licence’ version for the laptop you will be attending the course with from RStudio.com. If you have time before the course, it would be hugely beneficial to get familiar with RStudio. Objectives: Download R from https://www.stats.bris.ac.uk/R/. Download RStudio from https://www.rstudio.com/products/rstudio/#Desktop. If you found this guide useless. please follow this alternative guide here and let me know in the session that my guide sucks. 2.2 Basics R studio contains four panels: a script panel where you can save your code (we will introduce this later so to begin there will just be three panels), a console where you can enter and run your code and where the outputs are displayed, an environment which lists the objects you create, and another window which includes help, files and displays any plots you create. Our course starts in the R console, which those of you who are familiar with R but not RStudio will recognise. We will enter commands as input into the console, and receive output from the console. We will start with some simple basic operations, for which R is clearly very excessive. 2.2.1 Basic operations Entering 1+1, we get the output [1] 2. The output is 2, but the [1] lets us know that the number 2 is the first number of output. If we had an output that was particularly large (e.g. 100 seperate numbers) then r may let us know that the first row displayed starts with the first value [1] and the second row starts with the [x]th value. # add 1 to 1. 1 + 1 ## [1] 2 # divide 12 by 4 12/4 ## [1] 3 # times 3 by 7 3*7 ## [1] 21 # 10 to the power 3 10^3 ## [1] 1000 # root isn&#39;t a basic operation so we will look at this later. 2.2.2 Objects R is object orientated, which bascially means when we work in R we are generally writing code to make changes to an object (e.g. a dataset), based on other objects. An object can take a number of forms (e.g. a number, a vector of numbers, a matrix, a data-frame). We can then use these objects going forward rather than the values directly. Operations can be applied to these objects, and objects can be over-written. If you understand how to manipulate objects you are most of the way there. # create an object x which is 3 x &lt;- 3 # create an object y which is 5 y &lt;- 5 # add x and y x + y ## [1] 8 # overwrite x so it now equals 4. x &lt;- 4 # add x and y again, now the result is 9, not 7. x + y ## [1] 9 # create another object z which is equal to x + y at this time. z &lt;- x + y z ## [1] 9 2.2.3 Overwriting / Manipulating Objects We can overwrite our objects. But be careful, just because we overwrite something doesn’t mean other objects created in the code before update. # create an object a which is 10. a &lt;- 10 a ## [1] 10 # add one to a. A is now 11. a &lt;- a + 1 a ## [1] 11 # create an object called b which is 5 less than a b &lt;- a - 5 b ## [1] 6 # change a to be 5 less than it was originally a &lt;- a - 5 a-b ## [1] 0 # a and b are equal!!! 2.2.4 Seeing our Objects Sometimes we have so many objects we can’t see them in the environment. # prints the objects in the environment ls() ## [1] &quot;a&quot; &quot;b&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; 2.2.5 Removing Objects # sometimes we may want to remove an object. rm(a) # multiple objects at once rm(x,y) # remove all objects rm(list=ls()) Exercises 1a)Create an object d equal to 10. Divide d by 5. Multiply d by 8. Add 8 to d. What is d? 2a) Create an object m equal to 7. Overwrite m with m = m times 10. Create an object p equal to 2. d)Overwrite p with p = p times 12. Create an object w equal to m divided by p. What values do m, p and w take? 2.2.6 Evaluations We can perform evaluations, which provide a true or false answer. For example the input 4&gt;2 returns “FALSE”. It can be very useful in cases where an outcome is binary (e.g. an individual dies or remains alive). Or where we want to change a continous variable to a binary. # simple evaluations # 4 is greater than 2 4 &gt; 2 ## [1] TRUE # 4 is greater than 5 4 &gt; 5 ## [1] FALSE # 4 is equal to 3, note double == for an evaluation 4 == 3 ## [1] FALSE # 4 is not equal to 3, note != is not equal to. 4 != 3 ## [1] TRUE # the character x is equal to the character x. &quot;dog&quot; == &quot;dog&quot; ## [1] TRUE &quot;dog&quot; == &quot;cat&quot; ## [1] FALSE # the output from an evaluation can be stored as an object, x. This object can be subject to operations &amp; manipulations. b &lt;- 4&lt;2 b ## [1] FALSE Exercises Use R to answer the following questions for you: 1) Is 4 greater than 2? 2) Is 5 less than 3? 3) Is 6.2 equal to 12.4/2? 4) Is 5 equal to or greater than 4? (hint: use &gt;=) 5) Is 5 equal to or less than 5? (hint: use &lt;=) 2) Is 7.5 equal to 137.25/18? 3) m = 84 / 106, q = 156/3, is m/q greater than, less than or equal to 0.0152? 2.3 Object classes and types So far we have mostly been working with objects of a single numeric value. However, objects don’t have to take a single value, for example an object could be a vector of the heights of each child in a group of children. We have mostly been working with numeric values (vectors of one). As we have already seen, objects don’t have to be numeric. To illustrate the different classes we are going to create some vectors of different classes which we will then join together later to make a dataframe. 2.3.1 Object Classes Different classes include: numeric, character, factor, logical, integer &amp; complex (ignore). We can create a vector using the function c() which concatenates objects. We can type ?c() to ensure we understand what c() does. Typing ?function gives us the help file for any function. # numeric height &lt;- c(1.38,1.45,1.21,1.56) height ## [1] 1.38 1.45 1.21 1.56 # numeric weight &lt;- c(31,35,28,40) weight ## [1] 31 35 28 40 class(weight) ## [1] &quot;numeric&quot; # character first_name &lt;- c(&quot;Alice&quot;,&quot;Bob&quot;,&quot;Harry&quot;,&quot;Jane&quot;) first_name ## [1] &quot;Alice&quot; &quot;Bob&quot; &quot;Harry&quot; &quot;Jane&quot; #first_name + 1 # error # factor sex &lt;- factor(x = c(&quot;F&quot;,&quot;M&quot;,&quot;M&quot;,&quot;F&quot;)) sex ## [1] F M M F ## Levels: F M # logical tall &lt;- height &gt; 1.5 2.3.2 Operations on different data structures We can perform operations on the different objects with different structures, lengths, classes etc. It is important to know what can be done to objects. #Adding: c(1,2,3) + 1 ## [1] 2 3 4 c(1,2,3) + c(1,2,3) ## [1] 2 4 6 #multiplication heightft &lt;- height*3.28 # concatenating c(height,weight) ## [1] 1.38 1.45 1.21 1.56 31.00 35.00 28.00 40.00 # concatenating to string c(height,weight,first_name) ## [1] &quot;1.38&quot; &quot;1.45&quot; &quot;1.21&quot; &quot;1.56&quot; &quot;31&quot; &quot;35&quot; &quot;28&quot; &quot;40&quot; &quot;Alice&quot; ## [10] &quot;Bob&quot; &quot;Harry&quot; &quot;Jane&quot; Exercises Create a vector called ‘odds’ with the numbers 1,3,5,7,9. Show what class odds is. Evaluate which numbers in the odds vector are greater than 4. Create a vector called ‘fail’ containing 1,3,5,‘seven’,9. Show what class fail is. Create a vector that gives everyone’s weight in pounds (2.2lbs to kg) 2.3.3 Basic object Types There are multiple types of object in R. We can store objects together in a data-frame. In our example data-frame each column is a variable (height, weight, first_name), and each row is an individual. Different object types include: Vector - single variable is a 1x1 vector. All elements are the same class. Matrix - all elements are the same class. Dataframe - columns are vectors of the same class. Rows are lists. List - anything goes. We will ignore these for now. # data frame- columns are variables, rows are observations. df &lt;- data.frame(height,weight,first_name,sex) df ## height weight first_name sex ## 1 1.38 31 Alice F ## 2 1.45 35 Bob M ## 3 1.21 28 Harry M ## 4 1.56 40 Jane F # we can select a single variable within the dataframe using the dollar sign. df$height ## [1] 1.38 1.45 1.21 1.56 # We can add a new variable easily, in this case based on other variables within the dataframe. df$bmi &lt;- df$weight / df$height^2 df ## height weight first_name sex bmi ## 1 1.38 31 Alice F 16.27809 ## 2 1.45 35 Bob M 16.64685 ## 3 1.21 28 Harry M 19.12438 ## 4 1.56 40 Jane F 16.43655 2.3.4 Subsetting We can subset our data, to reduce it to those we are interested in. This is useful when cleaning our data, and when changing a continuous variable to a categorical. # Our data-frame contains the height, weight, first name and bmi of 4 individuals. df ## height weight first_name sex bmi ## 1 1.38 31 Alice F 16.27809 ## 2 1.45 35 Bob M 16.64685 ## 3 1.21 28 Harry M 19.12438 ## 4 1.56 40 Jane F 16.43655 #To subset a data frame we can use square brackets i.e df[row,column] #Selecting a column(s) df$height ## [1] 1.38 1.45 1.21 1.56 df[,&quot;height&quot;] ## [1] 1.38 1.45 1.21 1.56 df[,1] ## [1] 1.38 1.45 1.21 1.56 df[,1:3] ## height weight first_name ## 1 1.38 31 Alice ## 2 1.45 35 Bob ## 3 1.21 28 Harry ## 4 1.56 40 Jane df[,c(1,3)] ## height first_name ## 1 1.38 Alice ## 2 1.45 Bob ## 3 1.21 Harry ## 4 1.56 Jane #selecting a row(s) df[1,] ## height weight first_name sex bmi ## 1 1.38 31 Alice F 16.27809 #We might also want to select observations (rows) based on the characteristics of the data #E.g. we might want to only look at the data for people who are taller than 1.75m #create a logical variable called min_height which contains T/F for each individual being over 175cm. min_height &lt;- df$height &gt;= 1.75 min_height ## [1] FALSE FALSE FALSE FALSE # Subset the data to include only those observations (rows) for which height &gt; 175cm (using min_height). df.at_least_175 &lt;- df[min_height,] df.at_least_175 ## [1] height weight first_name sex bmi ## &lt;0 rows&gt; (or 0-length row.names) #People smaller than 1.75m # Subset the data to include only those who are not above min-height of 175cm. smaller &lt;- df$height &lt; 1.75 df[smaller,] ## height weight first_name sex bmi ## 1 1.38 31 Alice F 16.27809 ## 2 1.45 35 Bob M 16.64685 ## 3 1.21 28 Harry M 19.12438 ## 4 1.56 40 Jane F 16.43655 df[!min_height,] ## height weight first_name sex bmi ## 1 1.38 31 Alice F 16.27809 ## 2 1.45 35 Bob M 16.64685 ## 3 1.21 28 Harry M 19.12438 ## 4 1.56 40 Jane F 16.43655 Note that there are other more advanced methods, which uses pipes and require less code (these are covered in more advanced courses). Exercises Select the 3rd row from the data frame Select the weight variable from the data frame using your prefered method. Select alice’s data from the data frame. Subset the data frame to show just the data for the females type df[,-1], what does this give you? 2.3.5 Independent Exercises Exercise 1 Calculate the following: 5*10 20/3 Calculate x where a = 20 b = 9, c = 5, d = 1.2 \\(x = 4b + 7c + 3d\\) \\(x = \\frac{8b + 4c -12d}{a}\\) Exercise 2 x &lt;- c(10,30,4,52,60,7,8,10,12,15,14,17,19,20,25,30) Which numbers in x are above 8. Which numbers are equal to 10. Which numbers are below 8 or above 30. Can you create a matrix with numbers and characters. names &lt;- c(“Anne”,“Tom”,“Jamie”,“Max”,“Claire”) ages &lt;- c(12,16,25,34,28) cbind(names,ages) What happens if you try to use the ages? Create a dataframe for five individuals (Andrew, Betty, Carl, Diane and Elisa) who are aged (62,80,24,40,56) and have gender (male, female, male, female, female). Use evaluations and subsetting to find the characteristics of the individual who can claim their free bus pass (age 65+). Create a variable in the dataframe called life expectancy, set this to 83 for females and 80 for males. Create another variable called lyr (life years remaining) which is the number of years to life expectancy for each individual 2.4 Working with Data in R 2.4.1 Keeping Track of progress in R So far we have been working exclusively in the R console. This is useful for trialing code and doing quick intial analyses, however, the code we have typed is not saved for when we might look back at it in the future. If we want to keep a permanent record of our code, we can do this using a r-script. An r-script is basically a text-file containing lines of r-code. Usually we create them from scratch within R, though they can be created by importing a text file from text editor. The easiest way to create an r-file is by clicking the button in the top left corner of RStudio that looks like a piece of paper with a green plus over it. The use of # for commenting is common. For example below getwd() # this line of code sets the working directory. paste(&quot;RRRRR&quot;) # this line of code pastes RRRRR. #paste(&quot;RRRR&quot;) # this line doesn&#39;t # One is enough, but sometimes I can use a few to make the code tidy, like below. #==== # Section 1 #==== 2.4.1.1 Setting Working Directory When we use R, it is always associated with a specific directory within our computer. The place that R is associated with is known as the working directory. The working directory is the default place where R will look when we try to import (export) objects into R as well as the place that files are saved to. We can find out which directory R is pointed at by using the getwd() function: getwd() ## [1] &quot;C:/Users/Robert/Google Drive/Teaching/R Course/R4PHE&quot; If you know that you will be reading and writing multiple files from and to the same folder, you can set the working directory to that folder. This can be useful when a project has many different r-files and associated items such as data, functions, plots etc. In this case, one can set the working directory to the folder containing the files to make sure that everything stays in one place. It is also useful for when projects are shared between individuals using different computers, as setting the working directory to the shared folder prevents any isses that could arise from people organising their files in different ways. A new working directory can be set by clicking on the tab (Session) then (Set_Working Directory), or by the command setwd. Below I give the example of setting the working directory to my documents. filename = &quot;C:/Users/Robert/Google Drive/Teaching/R Course/Intro_to_R&quot; setwd(filename) getwd() 2.4.2 Importing Data In almost every project, you will want to import some data to analyse. This data will come in a variety of formats. R studio has a nice feature in Environment&gt;Import_Dataset which enables you to select the file you wish to download (similar to STATA) from your computer. The data is then imported into R and the code that R has used is displayed in the console. It is possible to import files in the following formats: Type Suffix R .R CSV .csv Excel .xls/.xlsx SPSS .spv Stata .dta If we want more control over the way that R imports the data we can also use the necessary commands in R directly. Some important examples of this are given in the next subsections. In addition, packages can be installed to import data in almost any format. Packages are collections of R functions and code in an organised framework. The directory where packages are stored on your computer is called the library. For example the readr package which allows for easier reading of data can be installed from the internet using the code install.packages(“readr”), then loaded into R using library(readr). 2.4.2.1 CSV (Comma-seperated values) A common format of data that you will likely import is comma-seperated values (CSV) data. CSV Data is seperated by commas in rows. For example: Age,Name,Sex, 30,Richard,Male, 27,Hazel,Female, 28,Louise,\"\", Creates: Age Name Sex 30 Richard Male 27 Hazel Female 28 Louise We can import the file using the full path with the file name and suffix included such as below. This will look in the working directory for the file specified, so given our working directory is “C:/Users/Robert/Documents” R will look in the Documents folder for the file “car_Data.csv”. It will then convert the first row to be the header of the data. There are numerous other options which we will skip for now. # car_Data &lt;- read.csv(file = &quot;car_Data.csv&quot;, header = TRUE) # if you couldn&#39;t get that to work don&#39;t worry, this is an example dataset from base R. car_Data &lt;- mtcars 2.4.2.2 Downloading files from the internet Sometimes it is more practical to download files directly from the internet. There are lots of different packages out there to do this. The one I use was developed by Hadley Wickham, called readr. Below we are going to download some data from the course github page. Github is a hosting service for source code (in this case R code), it allows users to store code, data and other files. This aids version control, collaboration, replication and consistency of material over time, # load the readr package, if this is not installed then install it. #install.packages(&quot;readr&quot;) library(readr) #use the function read_csv car_Data &lt;- read_csv(&quot;https://raw.githubusercontent.com/RobertASmith/Intro_to_R/master/car_Data.csv&quot;, header = TRUE) Downloading files directly to R within the same script as the analysis can be useful since it reduces the risk of you accidently changing the file. Just be careful that the data will always be available. 2.4.3 Summarising Data Once we have our data read into R, we want to ensure that the data is as we would expect, in the correct format etc. We can use the function head to look at the first 6 number of lines of the data. We can specify a different number of lines by changing the function input. # head data with default 6 rows head(car_Data) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # head data with 10 rows head(car_Data, n = 10) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 We can summarise a dataset using the function summary. This shows us the length, class and Mode. If the class is numeric it will give some indication of the distribution by displaying min, median, mean, max. # summarise the data, summary(car_Data) ## mpg cyl disp hp ## Min. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0 ## 1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5 ## Median :19.20 Median :6.000 Median :196.3 Median :123.0 ## Mean :20.09 Mean :6.188 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :8.000 Max. :472.0 Max. :335.0 ## drat wt qsec vs ## Min. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000 ## Median :3.695 Median :3.325 Median :17.71 Median :0.0000 ## Mean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000 ## Max. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000 ## am gear carb ## Min. :0.0000 Min. :3.000 Min. :1.000 ## 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000 ## Median :0.0000 Median :4.000 Median :2.000 ## Mean :0.4062 Mean :3.688 Mean :2.812 ## 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000 ## Max. :1.0000 Max. :5.000 Max. :8.000 # summarise single variable summary(car_Data$mpg) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 10.40 15.43 19.20 20.09 22.80 33.90 We can use the output of the summary function to create objects. The summary of the mpg variable gives the quantiles. These can be stored as an object, here called temp (temporary object). If we just want any one number from the vector of quantiles we can define this in brackets. The script below creates two new objects, median and range. temp &lt;- summary(car_Data$mpg) Median &lt;- temp[&#39;Median&#39;] Range &lt;- temp[&#39;Max.&#39;] - temp[&#39;Min.&#39;] 2.4.4 Plotting Data Line Plot R also has wide ranging plotting capabilites. For basic plotting we can use the plot function. In this next example, we will prodcue a simple plot of miles per gallon vs engine displacement in our data set to see what the relationship between the variables. #plot of mpg vs disp plot(x = car_Data$disp, y = car_Data$mpg) #notice we can remove arguments and still get same result plot(car_Data$disp, car_Data$mpg) Whilst this plot is useful, it is quite basic. We make the plot more informative by specifying extra features that we want when we call the plot function. We can add labels, titles, lines of best fit and more. plot(x = car_Data$disp, y = car_Data$mpg, type = &quot;p&quot;, xlab = &quot;Displacement&quot;, ylab = &quot;Miles per Gallon&quot;, main = &quot;MPG vs Engine Displacement&quot;) Sometimes we may just want to see the distribution of a single variable in the data. For numerical variables this is done easily by using plotting a histogram. To plot a histogram in R we use the command hist. hist1 &lt;- hist(car_Data$mpg) #We can alter the &#39;bins&#39; by specifying the additional argument &#39;breaks = &#39; in the hist function hist(car_Data$mpg, breaks = c(10,12.5,15,17.5,20,22.5,25,27.5,30,32.5,35)) #a neater way of doing the same as above is to use seq hist(car_Data$mpg, breaks = seq(10,35, by = 2.5)) #we can again edit the title etc by adding extra arguments hist(car_Data$mpg, breaks = seq(10,35, by = 2.5), xlab = &quot;Miles per gallon&quot;, main = &quot;Histogram of Miles per Gallon&quot;) Excercises Exercise 1 Load the iris dataset from base R into an object called flowerData by running the code ‘flowerData &lt;- iris’ Output the first 10 rows of the data 3 What class of object does each variable belong to? 3 Plot a seperate histogram of the sepal length for each species. Add a title and labels to each so that you know which is which. 4 Do you see any large differences between the distributions? (Try changing the ‘breaks’ argument to see if this makes things clearer) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... 2.4.5 Troubleshooting in R 2.4.5.1 Errors When doing any sort of programming work, things often don’t perfectly on the first try. Unfortunately, making mistakes and learning from them is an important part of becomming a better programmer. The process of troubleshooting generally follows 4 main steps: Read the error message. Sometimes it will be obvious what the error is from the message itself allowing you to quickly go back to your code and correct it. Read the R documentation. If the error has arisen whilst using a particular function or package then the documentation for those functions and packages will often have all the answers you need to solve your issue. Reading help files (which can be found using help(###) or ?###) is an importnant part of gaining a better understanding of R so don’t skip this step, however tempting it is. Go on the internet. There are many useful places on the internet to get help with any issues you encounter. Copying the error message into a google search will often reveal that someone else has had the same issue as yourself, and more often than not there will be myriad solutions for you to implement from other helpful R users. StackOverflow is a particularly useful place to go looking for help. Ask for help directly. If no solutions for your issue (or one that is similar enough for you to work out how to solve it on your own) have been found then you can ask directly to places like StackOverflow for help. Bear in mind that you will need to create a simpler version of your code with just enough in it to re-create the error. People wont read thorugh thousadns of lines to help sort your error! More detail on these steps can be found at link and there are many other resources online that can help for any issues that you might encounter. hist(car_Data$Mpg) hist(as.factor(car_Data$cyl)) 2.4.5.2 Advice for R skill building Naturally at some point you will be faced with the challenge of doing something in R that you have have not done before, and so is outside your current skill level. The process for learning this new capability is very similar to that of trouble shooting: First, ask can you use the functions and packages that you have already in your R reportoire to solve the issue? Trying to solve your issue this way first will deepen your understanding the capabilites of R and each package and function within it. This step will likely involve lost of reading of R documentation, so don’t be tempted to skip this step! If you have tried this but you are just getting errors then go through stages 1 and 2 of the troubleshooting procedures outlined above. If doing steps 1 and 2 still has not brought you any success, then it’s time to go searching the internet for help. A quick google search of what you want to do will often reveal multiple ways to do whatever it is your trying, and again places like stack overflow are very helpful for this. It is tempting to skip straight to step three at times (and we would be lying if we said we didn’t sometimes do it ourselves) but it’s better to resist. Doing steps 1 and 2 will allow you to work out which of the solutions available online is best for you, and the greater understanding you develop by taking this longer route will make you a better programmer in the long run, as you are more likely to understand the solutions given to you online. Overall this will open up the pathway to speedier problem solving in your code. Copying coded solutions off the internet to put in your work without understanding the limitations of your attempts or the how the solutions work may produce immediate results but at the sacrifice of your development as a programmer. 2.5 Further learning We hope to see you again on further courses with us at ScHARR. However, alternative resources are available: R for Data Science is a good place to recap the materials taught in this course. The hard copy of Hadley Wickham and Garrett Grolemund’s book of the same name (and content) is available on amazon An R user guide is available on the CRAN R-Project website here, although the author finds this less easy to follow than Hadley Wickham’s book described above. Also, you can learn R in R with swirl. Swirl has a range of short courses (approx 30mins) which are undertaken in R. You can download swirl by typing install.packages(“swirl”) into R. Once installed loading swirl from the library with library(swirl) and then following instructions within R. This course was created for educational purposes. The content was created by Robert Smith1, in collaboration with Paul Schneider1, Thomas Bayley1, Naomi Gibbs1, Sarah Bates1 and Amy Chang1. ** All errors are the responsibility of Robert Smith1, please send any feedback to rasmith3@sheffield.ac.uk.** 1Wellcome Trust Doctoral Training Centre, School of Health and Related Research, University of Sheffield "],
["intermediate-r.html", "Chapter 3 Intermediate R", " Chapter 3 Intermediate R Include intermediate content here. "],
["beautiful-visualizations-in-r.html", "Chapter 4 Beautiful Visualizations in R", " Chapter 4 Beautiful Visualizations in R Basic guide to ggplot for health data: 1) Line charts (Covid) 2) Scatter plots 3) Heatplots/Corrplots 4) Mapping "],
["markov-models.html", "Chapter 5 Markov Models", " Chapter 5 Markov Models Basic markov models, similar to HEDM Course but in 1 day. "],
["microsimulation-model.html", "Chapter 6 Microsimulation Model", " Chapter 6 Microsimulation Model Basic example of a microsimulation model in R. Microsim with one health state (dead/alive) Multiple simultaneous health states (e.g. Cancer + COPD) "],
["user-interfaces-for-health-economic-evaluation.html", "Chapter 7 User Interfaces for Health Economic Evaluation 7.1 Abstract 7.2 Introduction 7.3 Methods 7.4 Discussion 7.5 Conclusion", " Chapter 7 User Interfaces for Health Economic Evaluation Robert Smith1 &amp; Paul Schneider1 1ScHARR, University of Sheffield Corresponding Author: Robert Smith - rasmith3@sheffield.ac.uk 7.1 Abstract Health economic evaluation models have traditionally been built in Microsoft Excel, but more sophisticated tools are increasingly being used as model complexity and computational requirements increase. Of all the programming languages, R is most popular amongst health economists because it has a plethora of user-created packages and is highly flexible. However, even with an integrated development environments (e.g. R-Studio), R lacks a simple point-and-click user interface and therefore requires some programming ability. This might make the switch from Microsoft Excel to R seem daunting, and it might make it difficult to directly communicate results with decisions makers and other stakeholders. The R package Shiny has the potential to resolve this limitation. It allows programmers to embed health economic models developed in R into interactive web-browser-based user interfaces. Users can specify their own assumptions about model parameters and run different scenario analyses, which, in case of regular a Markov model, can be computed within seconds. This paper provides a tutorial on how to wrap a health economic model built in R into a Shiny application. We use a 4 state Markov model developed by the Decision Analysis in R for Technologies in Health (Workgroup 2020) group as a case-study to demonstrate main principles and basic functionality. A more extensive tutorial, all code, and data are provided in a GitHub repository: https://robertasmith.github.io/healthecon_shiny/. 7.2 Introduction As the complexity of health economic models increase, there is growing recognition of the advantages of using high level programming languages to support statistical analysis (e.g. R, Python, C++, Julia). Depending on the model that is being used, Microsoft Excel can be relatively slow. Certain types of models (e.g. individual-level simulations) can take a very long time to run or become computationally infeasible, and some essential statistical methods can hardly be implemented at all (e.g. survival modelling, network meta analysis, value of sample information), and rely on exporting results from other programs (e.g. R, STATA, WinBUGs). Of all the high level programming languages, R is the most popular amongst health economists (Jalal et al. 2017). R is open source, supported by a large community of statisticians, data scientists and health economists. There are extensive collections of (mostly free) online resources, including packages, tutorials, courses, and guidelines. Chunks of code, model functions, and entire models are shared by numerous authors, which allow R users to quickly adopt and adapt methods and code created by others. Importantly for the UK, R is also currently the only programming environment accepted by NICE for HTA submissions, the alternative submission formats Excel, DATA/TreeAge, and WinBUGS are all software applications (Health and Britain) 2014). Despite the many strengths of the script-based approach (e.g R) to decision modelling, an important limitation has been the lack of an easy-to-understand user-interface which would be useful as it “facilitates the development and communication of the model structure” (Jalal et al. 2017, 743). While it is common practice for ‘spreadsheet models’ to have a structured front tab, which allows decision makers to manipulate model assumptions and change parameters to assess their impact on the results, up until recently, R models had to be adapted within script files or command lines. Released in 2012, Shiny is an R-package which can be used to create a graphical, web browser based interface. The result looks like a website, and allows users to interact with underlying R models, without the need to manipulate the source code (Beeley 2016). Shiny has already been widely adopted in many different areas and by various organisations, to present the results of statistical analysis (Gendron 2016). With health economics Shiny is currently being used to conduct network meta analysis (Owen et al. 2019) and value of information analysis (Strong, Oakley, and Brennan (2014); Baio, Berardi, and Heath (2017)). Using Shiny, it is possible to create flexible user interfaces which allow users to specify different assumptions, change parameters, run underlying R code and visualise results. The primary benefit of this is that it makes script based computer models accessible to those with no programming knowledge - opening models up to critical inquiry from decision makers and other stakerholders (Jansen, Incerti, and Linthicum 2019). Other benefits come from leveraging the power of R’s many publicly available packages, for example allowing for publication quality graphs and tables to be downloaded, user specific data-files uploaded and open-access data automatically updated. Shiny web applications for R health economic models seem particularly useful in cases where model parameters are highly uncertain or unknown, and where analysis may want to be conducted with hetrogeneous assumptions (e.g. for different populations). Once an R model and a Shiny application have been created, they can also be easily adapted, making it possible to quickly update the model when new information becomes available. While, from a transparency perspective, it is preferable that models constructed in R are made open-access to improve replicability and collaboration, it is not a requirement (Hatswell and Chandler 2017). Sensitive and proprietary data and/or models can be shared internally, or through password-protected web applications, negating the need to email zipped folders. Several authors have postulated that there is considerable potential in using Shiny to support and improve health economic decision making. Incerti et al. (2019) identified web applications as being an essential part of modelling, stating that they “believe that the future of cost-effectiveness modeling lies in web apps, in which graphical interfaces are used to run script-based models” (p. 577). Similarly, Baio and Heath (2017) predicted that R Shiny web apps will be the “future of applied statistical modelling, particularly for cost-effectiveness analysis” (p.e5). Despite these optimistic prognoses, adoption of R in health economics has been slow and the use of Shiny seems to have been limited to only a few cases. A reason for this might be the lack of accessible tutorials, tailored towards an economic modeller audience. Here, we provide a simple example of a Shiny web app, using a general 4-state Markov model. The model is based on the ‘Sick-Sicker model’, which has been described in detail in previous publications (Alarid-Escudero et al. (2019); Alarid-Escudero et al. (2020)) and in open source teaching materials by the DARTH workgroup (Workgroup 2020). The model was slightly adapted to implement probabilistic sensitivity analysis. 7.3 Methods While the focus of this tutorial is on the application of Shiny for health economic models, below we provide a brief overview of the “Sick-Sicker model”. For further details, readers are encouraged to consult Alarid-Escudero et al. (2019), Alarid-Escudero et al. (2020), Krijkamp et al. (2018) and the DARTH group website (Workgroup 2020). The Sick-Sicker model is a 4 state (Healthy, Sick, Sicker or Dead) Markov model. The cohort progresses through the model in cycles of equal duration, with the proportion of those in each health state in the next cycle being dependant on the proportion in each health state in the current cycle and a constant transition probability matrix. The analysis incorporates probabilistic sensitivity analysis (PSA) by creating a data-frame of PSA inputs (one row being one set of model inputs) based on cost, utility and probability distributions using the function f_gen_psa and then running the model with each set of PSA inputs using the model function f_MM_sicksicker. We therefore begin by describing the two functions f_gen_psa and f_MM_sicksicker in more detail before moving on to demonstrate how to create a user-interface. Note that we add to the coding framework from Alarid-Escudero et al., (2019) to use the f_ prefix for functions. 7.3.1 Functions 7.3.1.1 Creating PSA inputs. The f_gen_psa function returns a data-frame of probabilistic sensitivity analysis inputs: transition probabilities between health states using a beta distribution, hazard rates using a log-normal distribution, costs using a gamma distribution and utilities using a truncnormal distribution. It relies on two inputs, the number of simulations (PSA inputs), and the cost (which takes a fixed value). We set the defaults to 1000 and 50 respectively. NOTE: in order to use the rtruncnorm function the user must first install and load the ‘truncnorm’ package using install.packages and library(). f_gen_psa &lt;- function(n_sim = 1000, c_Trt = 50){ df_psa &lt;- data.frame( # Transition probabilities (per cycle) p_HS1 = rbeta(n_sim, 30, 170), # prob Healthy -&gt; Sick p_S1H = rbeta(n_sim, 60, 60) , # prob Sick -&gt; Healthy p_S1S2 = rbeta(n_sim, 84, 716), # prob Sick -&gt; Sicker p_HD = rbeta(n_sim, 10, 1990) , # prob Healthy -&gt; Dead hr_S1 = rlnorm(n_sim, log(3), 0.01), # rate ratio death S1 vs healthy hr_S2 = rlnorm(n_sim, log(10), 0.02), # rate ratio death S2 vs healthy # Cost vectors with length n_sim c_H = rgamma(n_sim, shape = 100, scale = 20) , # cost p/cycle in state H c_S1 = rgamma(n_sim, shape = 177.8, scale = 22.5), # cost p/cycle in state S1 c_S2 = rgamma(n_sim, shape = 225, scale = 66.7) , # cost p/cycle in state S2 c_D = 0 , # cost p/cycle in state D c_Trt = c_Trt, # cost p/cycle of treatment # Utility vectors with length n_sim u_H = rtruncnorm(n_sim, mean = 1, sd = 0.01, b = 1), # utility when healthy u_S1 = rtruncnorm(n_sim, mean = 0.75, sd = 0.02, b = 1), # utility when sick u_S2 = rtruncnorm(n_sim, mean = 0.50, sd = 0.03, b = 1), # utility when sicker u_D = 0 , # utility when dead u_Trt = rtruncnorm(n_sim, mean = 0.95, sd = 0.02, b = 1) # utility when being treated ) return(df_psa) } 7.3.1.2 Running the model for a specific set of PSA inputs The function f_MM_sicksicker makes use of the with function which applies an expression (in this case the rest of the code) to a dataset (in this case params, which will be a row of PSA-inputs). It uses the params (one row of PSA inputs) to create a transition probability matrix m_P, and then moves the cohort through the simulation one cycle at a time, recording the proportions in each health state in a markov trace m_TR and applying the transition matrix to calculate the proportions in each health state in the next period m_TR[t+1,]. The function returns a vector of five results: Cost with no treatment, Cost with treatment, QALYs with no treatment and QALYs with treatment and an ICER. In this simple example treatment only influences utilities and costs, not transition probabilities f_MM_sicksicker &lt;- function(params) { with(as.list(params), { # compute internal parameters as a function of external parameter r_HD = - log(1 - p_HD) # rate of death in healthy r_S1D = hr_S1 * r_HD # rate of death in sick r_S2D = hr_S2 * r_HD # rate of death in sicker p_S1D = 1 - exp(-r_S1D) # probability to die in sick p_S2D = 1 - exp(-r_S2D) # probability to die in sicker # calculate discount weight for each cycle based on discount rate d_r v_dwe &lt;- v_dwc &lt;- 1 / (1 + d_r) ^ (0:n_t) # create transition probability matrix for NO treatment m_P &lt;- matrix(0, nrow = n_states, ncol = n_states, dimnames = list(v_n, v_n)) # fill in the transition probability array ### From Healthy m_P[&quot;H&quot;, &quot;H&quot;] &lt;- 1 - (p_HS1 + p_HD) m_P[&quot;H&quot;, &quot;S1&quot;] &lt;- p_HS1 m_P[&quot;H&quot;, &quot;D&quot;] &lt;- p_HD ### From Sick m_P[&quot;S1&quot;, &quot;H&quot;] &lt;- p_S1H m_P[&quot;S1&quot;, &quot;S1&quot;] &lt;- 1 - (p_S1H + p_S1S2 + p_S1D) m_P[&quot;S1&quot;, &quot;S2&quot;] &lt;- p_S1S2 m_P[&quot;S1&quot;, &quot;D&quot;] &lt;- p_S1D ### From Sicker m_P[&quot;S2&quot;, &quot;S2&quot;] &lt;- 1 - p_S2D m_P[&quot;S2&quot;, &quot;D&quot;] &lt;- p_S2D ### From Dead m_P[&quot;D&quot;, &quot;D&quot;] &lt;- 1 # create Markov trace (n_t + 1 because R doesn&#39;t understand Cycle 0) m_TR &lt;- matrix(NA, nrow = n_t + 1 , ncol = n_states, dimnames = list(0:n_t, v_n)) m_TR[1, ] &lt;- c(1, 0, 0, 0) # initialize Markov trace ############# PROCESS ########################################### for (t in 1:n_t){ # throughout the number of cycles # estimate the Markov trace for cycle the next cycle (t + 1) m_TR[t + 1, ] &lt;- m_TR[t, ] %*% m_P } ############ OUTPUT ########################################### # create vectors of utility and costs for each state v_u_trt &lt;- c(u_H, u_Trt, u_S2, u_D) v_u_no_trt &lt;- c(u_H, u_S1, u_S2, u_D) v_c_trt &lt;- c(c_H, c_S1 + c_Trt, c_S2 + c_Trt, c_D) v_c_no_trt &lt;- c(c_H, c_S1, c_S2, c_D) # estimate mean QALys and costs v_E_no_trt &lt;- m_TR %*% v_u_no_trt v_E_trt &lt;- m_TR %*% v_u_trt v_C_no_trt &lt;- m_TR %*% v_c_no_trt v_C_trt &lt;- m_TR %*% v_c_trt ### discount costs and QALYs te_no_trt &lt;- t(v_E_no_trt) %*% v_dwe # 1x31 %*% 31x1 -&gt; 1x1 te_trt &lt;- t(v_E_trt) %*% v_dwe tc_no_trt &lt;- t(v_C_no_trt) %*% v_dwc tc_trt &lt;- t(v_C_trt) %*% v_dwc results &lt;- c(&quot;Cost_NoTrt&quot; = tc_no_trt, &quot;Cost_Trt&quot; = tc_trt, &quot;QALY_NoTrt&quot; = te_no_trt, &quot;QALY_Trt&quot; = te_trt, &quot;ICER&quot; = (tc_trt - tc_no_trt)/(te_trt - te_no_trt)) return(results) } ) } 7.3.2 Creating the model wrapper When using a web application it is likely that the user will want to be able to change parameter inputs and re-run the model. In order to make this simple, we recommend wrapping the entire model into a function. We call this function f_wrapper, using the prefix f_ to denote that this is a function. The wrapper function has as its inputs all the parameters which we may wish to vary using R-Shiny. We set the default values to those of the base model in any report/publication. The model then generates PSA inputs using the f_gen_psa function, creates an empty table of results, and runs the model for each set of PSA inputs (a row from df_psa) in turn. The function then returns the results in the form of a dataframe with n=5 columns and n=psa rows. The columns contain the costs and qalys for treatment and no treatment for each PSA run, as well as an ICER for that PSA run. f_wrapper &lt;- function( #================================================================ # User adjustable inputs #================================================================ n_age_init = 25, # age at baseline default is 25 n_age_max = 110, # maximum age of follow up default is 110 d_r = 0.035, # discount rate for costs &amp; QALYS (NICE 3.5%) n_sim = 1000, # number of simulations default 1000 c_Trt = 50 # cost of treatment default 50 ){ #================================================================ # Unadjustable inputs #================================================================ n_t &lt;- n_age_max - n_age_init # time horizon, number of cycles v_n &lt;- c(&quot;H&quot;, &quot;S1&quot;, &quot;S2&quot;, &quot;D&quot;) # the 4 health states of the model: n_states &lt;- length(v_n) # number of health states #================================================================ # Create PSA Inputs #================================================================ df_psa &lt;- f_gen_psa(n_sim = n_sim, c_Trt = c_Trt) #================================================================ # Run PSA #================================================================ # Initialize matrix of results outcomes m_out &lt;- matrix(NaN, nrow = n_sim, ncol = 5, dimnames = list(1:n_sim,c(&quot;Cost_NoTrt&quot;, &quot;Cost_Trt&quot;, &quot;QALY_NoTrt&quot;, &quot;QALY_Trt&quot;, &quot;ICER&quot;))) # loop through psa inputs running the model for each. for(i in 1:n_sim){ # store results in one row of results matrix m_out[i,] &lt;- f_MM_sicksicker(df_psa[i, ]) # display the progress of the simulation cat(&#39;\\r&#39;, paste(round(i/n_sim * 100), &quot;% done&quot;, sep = &quot; &quot;)) } #================================================================ # Return results #================================================================ df_out &lt;- as.data.frame(m_out) # convert matrix to dataframe (for plots) return(df_out) # output the dataframe from the function } 7.3.3 Integrating into R-Shiny The method so far has involved wrapping the model into a function, which takes some inputs and returns a single data-frame output. The next step is to integrate the model function into a Shiny web-app. This is done within a single R file, which we call app.R. This can be found here: https://github.com/RobertASmith/healthecon_shiny/tree/master/App. The app.R script has three main parts, each are addressed in turn below: - set-up (getting everything ready so the user-interface and server can be created) - user interface (what people will see) - server (stuff going on in the background) As shown in Figure 1 below, the parameters which are varied in the user interface are a subgroup of inputs into the wrapped up model (the rest of the inputs coming from within the server). The model function has one output, a table of results, which are used within the server to create tables and plots. These are sent back to the user interface to be displayed as shiny outputs. 7.3.3.1 Set-up The set-up is relatively simple, load the R-Shiny package from your library so that you can use the shinyApp function. The next step is to use the source function in baseR to run the script which creates the f_wrapper function, being careful to ensure your relative path is correct (‘./wrapper.R’ should work if the app.R file is within the same folder). The function shinyApp at the end of the app file is reliant on the shiny package so please ensure that the shiny package is installed, using install.packages(“shiny”) if it is not. # install.packages(&quot;shiny&quot;) # necessary if you don&#39;t already have the function &#39;shiny&#39; installed. # we need the function shiny installed, this loads it from the library. library(shiny) # source the wrapper function. source(&quot;./wrapper.R&quot;) 7.3.3.2 User Interface The user interface is extremely flexible, we show the code for a very simple structure (fluidpage) with a sidebar containing inputs and a main panel containing outputs. We have done very little formatting in order to minimize the quantity of code while maintaining basic functionality. In order to get an aesthetically pleasing application we recommend much more sophisticated formatting, relying on CSS, HTML and Javascript. The example user interface displayed in Figure 2 and online at https://robertasmith.shinyapps.io/sick_sicker/. It is made up of two components, a titlepanel and a sidebar layout display. The sidebarLayout display has within it a sidebar and a main panel. These two components are contained within the fluidpage function which creates the user interface (ui). The title panel contains the title “Sick Sicker Model in Shiny”, the sidebar panel contains two numeric inputs and a slider input (“Treatment Cost”, “PSA runs”, “Initial Age”) and an Action Button (“Run / update model”). The values of the inputs have ID tags (names) which are recognised and used by the server function, we denote these with the prefix “SI” to indicate they are ‘Shiny Input’ objects (SI_c_Trt, SI_n_sim, SI_n_age_init). Note that this is an addition of the coding framework provided by Alarid-Escudero et al., (2019). The action button also has an id, this is not an input into the model wrapper (f_wrapper) so we leave out the SI and call it “run_model”. The main panel contains two objects which have been output from the server: tableOutput(“SO_icer_table”) is a table of results, and plotOutput(“SO_CE_plane”) is a cost-effectiveness plane plot. It is important that the format (e.g. tableOutput) matches the format of the object from the server (e.g. SO_icer_table). Again, the SO prefix reflects the fact that these are Shiny Outputs. The two h3() functions are simply headings which appear as “Results Table” and “Cost-effectiveness Plane”. #================================================================ # Create User Interface #================================================================ ui &lt;- fluidPage( # creates empty page, which we will fill titlePanel(&quot;Sick Sicker Model in Shiny&quot;), # title of app # SIDEBAR sidebarLayout( # indicates layout is going to be a sidebar-layout sidebarPanel( # open sidebar panel numericInput(inputId = &quot;SI_c_Trt&quot;, # id of input, used in server label = &quot;Treatment Cost&quot;, # label next to numeric input value = 200, # initial value min = 0, # minimum value allowed max = 400), # maximum value allowed numericInput(inputId = &quot;SI_n_sim&quot;, # id of input, used in server label = &quot;PSA runs&quot;, # label next to numeric input value = 1000, # initial value min = 0, # minimum value allowed max = 400), # maximum value allowed sliderInput(inputId = &quot;SI_n_age_init&quot;, # id of input, used in server label = &quot;Initial Age&quot;, # label next to numeric input value = 25, # initial value min = 10, # minimum value allowed max = 80), # maximum value allowed actionButton(inputId = &quot;run_model&quot;, # id of action button, used in server label = &quot;Run model&quot;) # action button label (on button) ), # close sidebarPanel mainPanel( # open main panel h3(&quot;Results Table&quot;), # heading (results table) tableOutput(outputId = &quot;SO_icer_table&quot;), # tableOutput id = icer_table, from server h3(&quot;Cost-effectiveness Plane&quot;), # heading (Cost effectiveness plane) plotOutput(outputId = &quot;SO_CE_plane&quot;) # plotOutput id = CE_plane, from server ) # close mainpanel ) # close sidebarlayout ) # close UI fluidpage 7.3.3.3 Server The server is marginally more complicated than the user interface. It is created by a function with inputs and outputs. The observe event indicates that when the action button (run_model) is pressed the code within the curly brackets is run. The code will be re-run if the button is pressed again. The first thing that happens when the run_model button is pressed is that the model wrapper function f_wrapper is run with the user interface inputs (SI_c_Trt, SI_n_age_init, SI_n_sim) as inputs to the function. The input$ prefix indicates that the objects have come from the user interface. The results of the model are stored as the dataframe object df_model_res. The ICER table is then created and output (note the prefix output$) in the object SO_icer_table. See previous section on the user interface and note that the tableOutput function has as an input SO_icer_table. The function renderTable rerenders the table continuously so that the table always reflects the values from the data-frame of results created above. In this simple example we have created a table of results using code within the script. In reality we would generally use a custom function which creates a publication quality table which is aesthetically pleasing. There are numerous packages which provide this functionality (e.g. BCEA, Darthpack, Heemod) The cost-effectiveness plane is created in a similar process, using the renderPlot function to continuously update a plot which is created using baseR plot function using incremental costs and QALYs calculated from the results dataframe df_model_res. For aesthetic purposes we recommend this is replaced by a ggplot or plotly plot which has much improved functionality. Again, there are packages available for this (e.g. Heemod, BCEA, Darthpack) #================================================================ # Create Server Function #================================================================ server &lt;- function(input, output){ # server = function with two inputs observeEvent(input$run_model, # when action button pressed ... ignoreNULL = F, { # Run model wrapper function with the Shiny inputs and store as data-frame df_model_res = f_wrapper(c_Trt = input$SI_c_Trt, n_age_init = input$SI_n_age_init, n_sim = input$SI_n_sim) #--- CREATE COST EFFECTIVENESS TABLE ---# output$SO_icer_table &lt;- renderTable({ # this continuously updates table df_res_table &lt;- data.frame( # create dataframe Option = c(&quot;Treatment&quot;,&quot;No Treatment&quot;), QALYs = c(mean(df_model_res$QALY_Trt),mean(df_model_res$QALY_NoTrt)), Costs = c(mean(df_model_res$Cost_Trt),mean(df_model_res$Cost_NoTrt)), Inc.QALYs = c(mean(df_model_res$QALY_Trt) - mean(df_model_res$QALY_NoTrt),NA), Inc.Costs = c(mean(df_model_res$Cost_Trt) - mean(df_model_res$Cost_NoTrt),NA), ICER = c(mean(df_model_res$ICER),NA) ) # round the dataframe to two digits so looks tidier df_res_table[,2:6] &lt;- round(df_res_table[,2:6],digits = 2) # print the results table df_res_table }) # table plot end. #--- CREATE COST EFFECTIVENESS PLANE ---# output$SO_CE_plane &lt;- renderPlot({ # render plot repeatedly updates. # calculate incremental costs and qalys from results dataframe df_model_res$inc_C &lt;- df_model_res$Cost_Trt - df_model_res$Cost_NoTrt df_model_res$inc_Q &lt;- df_model_res$QALY_Trt - df_model_res$QALY_NoTrt # create cost effectiveness plane plot plot(x = df_model_res$inc_Q, # x axis incremental QALYS y = df_model_res$inc_C, # y axis incremental Costs #label axes xlab = &quot;Incremental QALYs&quot;, ylab = &quot;Incremental Costs&quot;, # set xlimits and ylimits for plot. xlim = c(min(df_model_res$inc_Q,df_model_res$inc_Q*-1), max(df_model_res$inc_Q,df_model_res$inc_Q*-1)), ylim = c(min(df_model_res$inc_C,df_model_res$inc_C*-1), max(df_model_res$inc_C,df_model_res$inc_C*-1)), # include y and y axis lines. abline(h = 0,v=0) ) # plot end }) # renderplot end }) # Observe Event End } # Server end 7.3.3.4 Running the app The app can be run within the R file using the function shinyApp which depends on the ui and server which have been created and described above. Running this creates a Shiny application in the local environment (e.g. your desktop). In order to deploy the application onto the web the app needs to be published using the publish button in the top right corner of the R-file in RStudio (next to run-app). A step by step guide to this process can be found on the R-Shiny website https://shiny.rstudio.com/deploy/. ## ----- run app------ shinyApp(ui, server) 7.3.3.5 Additional Functionality The example Sick-Sicker web-app which has been created is a simple, but functional, R-Shiny user interface for a health economic model. There are a number of additional functionalities which we have used for various projects: ability to fully customise the aesthetics of the user interface similar to standard web-design. ability to upload files containing input parameters to the app before running the model. ability to download figures and tables from the app. ability to download a full markdown report which updates all numbers, tables and figures in the report based on the user inputs and model outputs. ability to select the comparitor and treatment(s) where multiple treatments exist. It is also possible to integrate network meta-analysis (NMA), the economic model, and value of information analysis (VOI) in a single application. After selecting NMA inputs (e.g. a subgroup of effectiveness studies) and economic model inputs (e.g. costs of treatments) and then clicking the ‘run’ button, a user would be presented with results of the NMA, economic model and VOI in one simple user-interface. They would then be able to download a report with all of the relevant information updated (e.g. numbers, tables, figures). We believe this is the future of health economics. 7.4 Discussion In this paper, we demonstrated how to generate a user-friendly interface for an economic model programed in R, using the Shiny package. This tutorial shows that the process is relatively simple and requires limited additional programming knowledge than that required to build a decision model in R. The movement towards script based health economic models with web based user interfaces is particularly useful in situations where a general model structure has been created with a variety of stakeholders in mind, each of which may have different input parameters and wish to conduct sensitivity analysis specific to their decision. For example the World Health Organisation Department of Sexual and Reproductive Health and Research recently embedded a Shiny application into their website https://srhr.org/fgmcost/cost-calculator/. The application runs a heemod model (Filipovic-Pierucci, Zarca, and Durand-Zaleski 2016) in R in an external server, and allows users to select their country and change country specific input parameters, run the model and display results. The process of engagement, the ability to ‘play’ with the model and test the extremes of the decision makers’ assumptions gives stakeholders more control over models, making them feel less like black boxes. While there is a danger that a mis-informed stakeholder may make a mistake in their choice of parameter, we should remember that the role of the model is to inform decision-makers not instruct them … and besides: it is simple to limit the range that parameter inputs can take. The authors’ experience of creating user-interfaces for decision models has led us to the conclusion that the most efficient method is to work iteratively, first ensuring that the model is working as intended before making incremental changes to the user interface and server one item at a time. While experienced programmers can make substantial time savings by combining multiple steps we have found that the time taken to correct mistakes far outweighs the time savings associated with combining steps. There are several challenges that exist with the movement toward script based models with web-based user-interfaces. The first is the challenge of upskilling health economists used to working in Microsoft Excel. We hope that this tutorial provides a useful addition to previous tutorials demonstrating how to construct decsion models in R (Alarid-Escudero et al. 2020). A second, and crucial challenge to overcome, is a concern about deploying highly sensitive data and methods to an external server. While server providers such as ShinyIO provide assurances of SSR encryption and user authentication clients with particularly sensitive data may still have concerns. This problem can be avoided in two ways: firstly if clients have their own server and the ability to deploy applications they can maintain control of all data and code, and secondly the application could simply not be deployed, and instead simply created during a meeting using code and data shared in a zip file. Finally, a challenge (and opportunity) exists to create user-interfaces that are most user-friendly for decision makers in this field, this is an area of important research which can be used to inform teaching content for years to come. 7.5 Conclusion The creation of web application user interfaces for health economic models constructed in high level programming languages should improve their usability, allowing stakeholders and third parties with no programming knowledge to conduct their own sensitivity analysis remotely. This tutorial provides a reference for those attempting to create a user interface for a health economic model created in R. Further work is necessary to better understand how to design interfaces which best meet the needs of different decision makers. References "],
["working-collaboratively.html", "Chapter 8 Working Collaboratively", " Chapter 8 Working Collaboratively Paper submitted to Wellcome Open Research "],
["references.html", "References", " References "]
]
